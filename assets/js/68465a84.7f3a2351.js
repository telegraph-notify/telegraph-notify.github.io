"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[249],{4133:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var n=i(4848),s=i(8453);const a={title:"Case Study",description:"Telegraph Case Study",toc_min_heading_level:2,toc_max_heading_level:3,className:"test"},r="Case Study",o={type:"mdx",permalink:"/case-study",source:"@site/src/pages/case-study.md",title:"Case Study",description:"Telegraph Case Study",frontMatter:{title:"Case Study",description:"Telegraph Case Study",toc_min_heading_level:2,toc_max_heading_level:3,className:"test"},unlisted:!1},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Building Notifications is Not Trivial",id:"building-notifications-is-not-trivial",level:2},{value:"Third-Party Solutions",id:"third-party-solutions",level:2},{value:"Introducing Telegraph",id:"introducing-telegraph",level:2},{value:"Step 1: Install dependencies &amp; deploy Telegraph to AWS",id:"step-1-install-dependencies--deploy-telegraph-to-aws",level:3},{value:"Step 2: Integrate frontend SDK",id:"step-2-integrate-frontend-sdk",level:3},{value:"Step 3: Send notifications with the backend SDK",id:"step-3-send-notifications-with-the-backend-sdk",level:3},{value:"Demo",id:"demo",level:3},{value:"Architecture",id:"architecture",level:3},{value:"Engineering Challenges and Decisions",id:"engineering-challenges-and-decisions",level:2},{value:"Real-time Communication with Clients",id:"real-time-communication-with-clients",level:3},{value:"Polling",id:"polling",level:4},{value:"Server-Sent Events &amp; WebSockets",id:"server-sent-events--websockets",level:4},{value:"Why WebSockets?",id:"why-websockets",level:4},{value:"Persistent Data Storage",id:"persistent-data-storage",level:3},{value:"Storage for high reads and writes",id:"storage-for-high-reads-and-writes",level:4},{value:"Storage for high writes and large volume",id:"storage-for-high-writes-and-large-volume",level:4},{value:"Authentication",id:"authentication",level:3},{value:"Key-based Authentication",id:"key-based-authentication",level:4},{value:"Hash-based Authentication",id:"hash-based-authentication",level:4},{value:"Observability",id:"observability",level:3},{value:"Traffic Spikes",id:"traffic-spikes",level:3},{value:"Load Testing",id:"load-testing",level:2},{value:"WebSocket Gateway",id:"websocket-gateway",level:3},{value:"HTTP Gateway",id:"http-gateway",level:3},{value:"Bottlenecks",id:"bottlenecks",level:3},{value:"Capacity",id:"capacity",level:3},{value:"Future Work",id:"future-work",level:2},{value:"Automated Key Rotation for HMAC Authentication",id:"automated-key-rotation-for-hmac-authentication",level:4},{value:"Stage-Specific Metrics",id:"stage-specific-metrics",level:4},{value:"Automating Retry Logic for Failed Deliveries",id:"automating-retry-logic-for-failed-deliveries",level:4},{value:"Footnotes",id:"footnotes",level:2},{value:"References",id:"references",level:2}];function d(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"case-study",children:"Case Study"}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(t.p,{children:"Telegraph is a self-hosted, serverless Notification as a Service (NaaS) designed to simplify the complexities of implementing and managing real-time notifications for web applications."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/overview.gif",className:"diagram",alt:"architectural-overview"})}),"\n",(0,n.jsx)(t.p,{children:"Notifications may seem simple on the surface. They\u2019re just a way to keep users informed on things like a shipped package, an upcoming meeting, or a flash sale. Whenever one of these events happens, you send a message to your user. But when you start digging into what it takes to build a notification system of your own, it becomes apparent that there\u2019s a lot more going on under the hood. It\u2019s not just about delivering a message. How do you make sure it works without bogging down the rest of your application? How do you make sure it works for every user, every time? These challenges are not always obvious until you\u2019re deep in the development process."}),"\n",(0,n.jsx)(t.p,{children:"This case study explores the technical foundation of Telegraph, focusing on the challenges of building a scalable and reliable notification service, the architectural trade-offs made during its development, and the benefits of adopting a serverless approach."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"building-notifications-is-not-trivial",children:"Building Notifications is Not Trivial"}),"\n",(0,n.jsx)(t.p,{children:"Notifications are messages triggered by an event within an application that are sent to subscribed users. They can be delivered over multiple notification channels, which may include: web-push, in-app, email, or Slack. The first step in building a notification system is deciding what should trigger a notification. What events matter to you or your users? From there, you need to build a logic diagram to determine if a notification should actually be sent. Maybe the user has unsubscribed from this event type, or they\u2019ve enabled do-not-disturb. Is the event critical enough to override those settings? It\u2019s not just a few decisions, either. Just look at Slack's notification logic diagram \u2013 figuring out when to send a notification can quickly become a maze of decision-making."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/slack-workflow.webp",className:"diagram",alt:"slack-workflow",width:"80%"})}),"\n",(0,n.jsxs)(t.p,{children:["Once you\u2019ve decided ",(0,n.jsx)(t.strong,{children:"when"})," to notify, the next challenge is ",(0,n.jsx)(t.strong,{children:"how"})," to deliver the message. Traditional HTTP request/response cycles aren\u2019t designed for proactively pushing data to users. If you want to send messages without waiting for users to request them, you\u2019ll need to make some architectural changes. And that\u2019s only the beginning."]}),"\n",(0,n.jsx)(t.p,{children:"On a normal day, your app and the notification system can share infrastructure without issues. But when usage spikes -- whether it\u2019s your app handling a flood of new users or the notification system sending out a burst of messages -- the story changes. Both systems are now competing for the same resources, and you could quickly run into capacity limits. What\u2019s worse is that these surges tend to happen together. When your app is busiest, notifications tend to be as well. This overlap can strain your infrastructure in ways that are hard to recover from during a critical moment. So, when you add notifications, you\u2019re also adding to your scaling concerns \u2013 and it\u2019s something you\u2019ll need to plan for."}),"\n",(0,n.jsx)(t.p,{children:'Finally, users expect notifications to "just work," but there\u2019s a lot that goes into making that happen. For developers, it\u2019s not just about sending a message. It\u2019s about making sure it actually gets delivered, keeping track of any failures, and knowing the status of each notification as it traverses through the system. What happens if something goes wrong during delivery? How do you know if the message reached its destination? These are things you\u2019ll need to consider, and building the systems to track them adds a whole new layer of complexity. It\u2019s easy to overlook this when you\'re focused on getting messages out the door, but without it, you\u2019re left in the dark about whether things are actually working.'}),"\n",(0,n.jsx)(t.p,{children:"When you step back and think about all of this, it quickly becomes apparent that building a notification system isn\u2019t just a quick add-on. It\u2019s a whole project that can take a lot more time and effort than you might have expected."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"third-party-solutions",children:"Third-Party Solutions"}),"\n",(0,n.jsx)(t.p,{children:"The good news is that you don't have to reinvent the wheel. There are plenty of services out there that specialize in notifications. Of course, third-party solutions come with their own set of trade-offs. You\u2019re giving up some control over how things work, and you might be tied to their pricing model. Open-source solutions may not have a recurring fee, but they\u2019re not entirely \u201cfree\u201d either. The real cost comes in the time it takes to get up and running with them. You could end up spending a lot of time just trying to integrate something open-source. However, in exchange, you get a system that\u2019s already built to handle all of the complexities mentioned above."}),"\n",(0,n.jsx)(t.p,{children:"Services like MagicBell, NotificationAPI, Novu, and Knock all bring something to the table. Knock and Novu are feature-rich, but they can be time-consuming to integrate. MagicBell and NotificationAPI are more straightforward, but their pricing starts at $100-$250/month and the free tiers come with mandatory branding. Another point of consideration is that using these services means storing user data on external systems, which may raise data privacy concerns."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.img,{alt:"Third-party comparison table",src:i(7644).A+"",width:"711",height:"288"}),"\n",(0,n.jsx)("figcaption",{align:"center",children:"Comparing Telegraph with other Third-party providers"})]})}),"\n",(0,n.jsx)(t.p,{children:"Telegraph stands out in four key areas against the existing solutions:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Open-source and self-hosted."}),"\n",(0,n.jsx)(t.li,{children:"Auto-deployment of all required AWS services with a CLI."}),"\n",(0,n.jsx)(t.li,{children:"Complete data ownership."}),"\n",(0,n.jsxs)(t.li,{children:["Minimizes costs with the on-demand features of AWS. ",(0,n.jsx)(t.a,{href:"#footnotes",children:"[1]"})]}),"\n"]}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"introducing-telegraph",children:"Introducing Telegraph"}),"\n",(0,n.jsx)(t.p,{children:"Telegraph is built for small to mid-sized applications that need to deliver real-time notifications. For developers choosing Telegraph, the service has pre-configured delivery channels and an observability dashboard for overseeing the service instance. Developers can then implement in-app, email, and Slack notifications into their applications with minimal structural changes to their existing infrastructure."}),"\n",(0,n.jsxs)(t.p,{children:["Telegraph is deployed to AWS via a CLI available as an npm package. Once deployed the backend SDK can be integrated in the customer\u2019s backend to send notification requests and the ",(0,n.jsx)(t.code,{children:"TelegraphInbox"})," React component can be added to the customer\u2019s frontend, enabling in-app notifications and notification preference management for users."]}),"\n",(0,n.jsx)(t.h3,{id:"step-1-install-dependencies--deploy-telegraph-to-aws",children:"Step 1: Install dependencies & deploy Telegraph to AWS"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:(0,n.jsx)(t.em,{children:"Install Telegraph CLI"})})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"$ npm install -g @telegraph-notify/telegraph-cli\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:(0,n.jsx)(t.em,{children:"Initialize Telegraph"})})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"$ telegraph init\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:(0,n.jsx)(t.em,{children:"Deploy to AWS"})})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"$ telegraph deploy\n"})}),"\n",(0,n.jsx)(t.h3,{id:"step-2-integrate-frontend-sdk",children:"Step 2: Integrate frontend SDK"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-jsx",children:'import { TelegraphInbox } from "@telegraph-notify/frontend-sdk";\n\n<App>\n  <TelegraphInbox\n    user_id={<USER_ID>} // Unique identifier of the logged in user\n    userHash={<USER_HMAC>} // Hashed user_id\n    websocketUrl={<WEBSOCKET_GATEWAY_URL>} // WebSocket Gateway URL\n  />\n</App>\n'})}),"\n",(0,n.jsx)(t.h3,{id:"step-3-send-notifications-with-the-backend-sdk",children:"Step 3: Send notifications with the backend SDK"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-typescript",children:'import Telegraph from "@telegraph-notify/backend-sdk";\n\n// Enter secret key and HTTP Gateway URL\nconst telegraph = new Telegraph(secretKey, httpGateway);\n\ntelegraph.send({\n  user_id,\n  channels: {\n   in_app?: {\n      message\n   },\n   email?: {\n      subject,\n      message,\n   },\n   slack?: {\n      message,\n   }\n }\n});\n'})}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"demo",children:"Demo"}),"\n",(0,n.jsx)(t.p,{children:"Here is what all of that looks like in action."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/demoapp.gif",className:"diagram",alt:"demoapp"})}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"architecture",children:"Architecture"}),"\n",(0,n.jsx)(t.p,{children:"Telegraph has a serverless architecture on AWS and uses services like API Gateway, Lambda, and DynamoDB to implement its service with minimal operational overhead."}),"\n",(0,n.jsxs)("figure",{className:"image-container",children:[(0,n.jsx)("img",{src:"/case-study/images/Architecture900.png",className:"diagram",alt:"Telegraph's architecture",width:"63%"}),(0,n.jsx)("figcaption",{align:"center",children:"Telegraph's Architecture"})]}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"engineering-challenges-and-decisions",children:"Engineering Challenges and Decisions"}),"\n",(0,n.jsx)(t.h3,{id:"real-time-communication-with-clients",children:"Real-time Communication with Clients"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/architecture_ws_gateway.png",className:"diagram",alt:"architecture-websocket"})}),"\n",(0,n.jsx)(t.p,{children:"One of the first decisions we had to make was how to send in-app notifications to the client. In the standard HTTP model, clients request data from servers as needed. In-app notifications, however, require real-time delivery, where the server pushes data to the client as events happen without waiting for a request."}),"\n",(0,n.jsx)(t.p,{children:"There are three primary mechanisms that can be used to achieve this: polling, Server-Sent Events (SSE), and WebSockets."}),"\n",(0,n.jsx)(t.h4,{id:"polling",children:"Polling"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/HTTP-Polling.png",className:"diagram",alt:"polling"})}),"\n",(0,n.jsx)(t.p,{children:"Polling is a mechanism in which a client periodically sends HTTP requests to a server to check for new data. However, frequent polling can strain both the server and the network. While increasing the interval between requests can alleviate that strain, it reduces the application's ability to deliver real-time updates. Additionally, as the user base grows, the number of unnecessary polling requests \u2013 those that return no new data \u2013 can result in a substantial waste of resources. Due to these inefficiencies, especially at scale, we opted not to use polling."}),"\n",(0,n.jsx)(t.h4,{id:"server-sent-events--websockets",children:"Server-Sent Events & WebSockets"}),"\n",(0,n.jsx)(t.p,{children:"Both SSEs and WebSockets establish a persistent connection between client and server and allow data to be pushed on-demand from the server to the client."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/SSE.png",className:"diagram",alt:"sse"})}),"\n",(0,n.jsx)(t.p,{children:"SSEs establish a long-lived HTTP connection between the client and server, enabling the server to push updates to the client as they occur and only terminate when requested by either party. Compared with WebSockets, SSE is simpler to implement, as it relies solely on standard HTTP without requiring additional libraries or protocols. This simplicity makes it easy to set up and debug. Furthermore, SSE provides built-in features like automatic reconnection and message ordering."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/WebSockets.png",className:"diagram",alt:"polling"})}),"\n",(0,n.jsx)(t.p,{children:"WebSocket is a communication protocol that establishes a long-lived, bidirectional connection between a client and server over a single TCP connection. Following the initial HTTP handshake, the client sends an upgrade request that transitions the connection to the WebSocket protocol. This protocol establishes a dedicated channel for two-way real-time communication, making WebSocket particularly well-suited for interactive use cases, such as real-time chat applications or collaborative tools."}),"\n",(0,n.jsx)(t.h4,{id:"why-websockets",children:"Why WebSockets?"}),"\n",(0,n.jsx)(t.p,{children:"We initially used SSEs to implement the sending of in-app notifications. The browser received these events from an Express backend server and then updated a user-facing frontend component to notify the user of this new event. This mechanism fulfilled our requirement to send in-app notifications in real-time. However, when we considered the scaling implications of using SSEs, and compared this with a serverless WebSocket architecture, we found WebSockets would serve Telegraph\u2019s use case better in the long term, particularly when considering the availability of AWS API Gateway for WebSockets."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/ScalingEC2.gif",className:"diagram",alt:"scaling-instances"})}),"\n",(0,n.jsx)(t.p,{children:"If we were to continue building Telegraph as a drop-in Notification as a Service using SSEs, we would have needed to set up an EC2 instance or similar compute resources. While this solution provides fine-grained control over scaling logic, connection management, and database infrastructure, we found it to lead to higher costs and complexity. For example, scaling an EC2-based setup would involve managing load balancers and provisioning distributed database systems or sharded architectures to handle the growth in notification data. These resources will incur costs even when idle. We estimated that in a hypothetical use case of delivering 100,000 notifications for 2,000 users, the monthly cost of the serverless architecture was about 1/3 of that of using EC2 instances."}),"\n",(0,n.jsx)(t.p,{children:"In addition to architectural components needing to scale up, as traffic drops and the number of connections reduces, they also need to scale down while maintaining the remaining connections. Although a single EC2 instance may be able to service all active SSE connections, we would not be able to consolidate the scattered connections without disconnecting them first. This would result in multiple EC2 instances running in underutilized states."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/ScalingWS.gif",className:"diagram",alt:"scaling-websockets"})}),"\n",(0,n.jsx)(t.p,{children:"In contrast, AWS\u2019s API Gateway Websocket API automatically handles scaling and connection persistence. The API Gateway and the attached lambdas scale up and down with demand, ensuring no redundant resources are left running that would drive up costs. This built-in scaling behavior of the API Gateway allowed us to focus on building the core functionality of Telegraph while minimizing the operational burden of managing infrastructure, making WebSockets the better choice for our notification system."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"persistent-data-storage",children:"Persistent Data Storage"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/architecture_databases.png",className:"diagram",alt:"websockets"})}),"\n",(0,n.jsx)(t.h4,{id:"storage-for-high-reads-and-writes",children:"Storage for high reads and writes"}),"\n",(0,n.jsx)(t.p,{children:"Our data for WebSocket connection IDs, user preferences and attributes, and in-app notifications has a fixed and consistent structure. It also does not require complex relational queries, primarily involving simple look-ups based on user ID. However, the nature of our workflow meant that the database solution needed to handle a high frequency of both reads and writes."}),"\n",(0,n.jsx)(t.p,{children:"By this point, we had already committed to using the WebSocket API Gateway, which influenced the rest of our architecture. As a result, we considered database services offered by AWS that could integrate with our serverless infrastructure. Although we could potentially use either NoSQL or SQL databases since our data is structured, we ultimately chose a NoSQL database, specifically DynamoDB, due to its ability to scale horizontally and handle high read and write throughput."}),"\n",(0,n.jsx)(t.h4,{id:"storage-for-high-writes-and-large-volume",children:"Storage for high writes and large volume"}),"\n",(0,n.jsx)(t.p,{children:"Another type of storage solution we needed to consider was for the tracing logs of notification requests. This storage solution would need to handle a high volume of writes and store a large number of small files."}),"\n",(0,n.jsx)(t.p,{children:"Initially, when considering storage for logs, Amazon\u2019s S3 bucket seemed like the best choice. S3 is a scalable object storage solution known for being particularly cost-effective for storing large amounts of data. However, after implementation, we quickly found that the number of reads to the S3 Bucket would be significant and, with about a 10x difference in read costs compared to DynamoDB, it could quickly become an expensive solution. We also found the query time of S3 to be a significant concern for our use case, as retrieving 20 objects, each about 30 bytes, resulted in a timeout due to Lambda's default 3-second execution limit."}),"\n",(0,n.jsx)(t.p,{children:"Given that we needed to query the logs database for viewing and error handling on the dashboard, the lag in retrievals and the cost difference for reads outweighed the cheap storage benefits of S3. As a result, we opted to use DynamoDB for our notification logs."}),"\n",(0,n.jsx)(t.p,{children:"Once our data was stored away, it was time to keep it safe."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"authentication",children:"Authentication"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/architecture_authorizers.png",className:"diagram",alt:"authorizors"})}),"\n",(0,n.jsx)(t.p,{children:"Telegraph uses two authentication methods: key-based authentication for server-side connections and Hash-Based Message Authentication Codes (HMAC) for client-side connections."}),"\n",(0,n.jsx)(t.h4,{id:"key-based-authentication",children:"Key-based Authentication"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/Key-Based-Authentication.gif",className:"diagram",alt:"key based authentication"})}),"\n",(0,n.jsxs)(t.p,{children:["Telegraph uses key-based authentication for API requests. During setup, users generate a secret key, which is included in the ",(0,n.jsx)(t.code,{children:"Authorization"})," header of each request and then verified by the HTTP Gateway authorizer."]}),"\n",(0,n.jsx)(t.h4,{id:"hash-based-authentication",children:"Hash-based Authentication"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/HMAC-Authentication.gif",className:"diagram",alt:"key based authentication"})}),"\n",(0,n.jsx)(t.p,{children:"Authenticating a client between two servers with a shared secret key is more challenging, since the credentials in the Authorization header are visible to the client. If the secret key is intercepted by a third party, they gain access to all Telegraph API functions."}),"\n",(0,n.jsxs)(t.p,{children:["Our solution uses hash-based message authentication codes (HMAC) ",(0,n.jsx)(t.a,{href:"#references",children:"[3]"})," to authenticate clients connecting to the WebSocket Gateway. The application server generates a unique hash for each client by combining the secret key and user ID using SHA256. When connecting to the WebSocket Gateway, the user ID and hash are passed to the WebSocket authorizer, which verifies it using the same algorithm as the application server."]}),"\n",(0,n.jsx)(t.p,{children:"You might be wondering why we didn\u2019t use JWTs or OAuth. After all, they\u2019re widely adopted across the industry for authentication. The choice came down to what Telegraph is optimized for. HMAC avoids the need for additional infrastructure like token servers or complex validation workflows. You only have to manage a shared secret key."}),"\n",(0,n.jsx)(t.p,{children:"JWTs and OAuth are powerful tools, but they\u2019re designed for different needs. JWTs are great in distributed systems where multiple services need to independently validate tokens without checking back with a central server. That flexibility is great if you need it, but it adds unnecessary complexity for Telegraph\u2019s needs. OAuth, on the other hand, is great for scenarios involving delegated access, like when users need to log in through a third-party provider. However, we designed Telegraph to be a single-tenant, self-hosted environment where your server already authenticates clients before Telegraph comes into the picture."}),"\n",(0,n.jsx)(t.p,{children:"That said, we did recognize that the secret key used in the HMAC process doesn\u2019t have a native expiration or rotation mechanism. We added a way for you to change the secret key whenever needed through the CLI \u2013 whether it\u2019s in response to a security breach or simply because the key has been in use for a while and you want to rotate it out."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"observability",children:"Observability"}),"\n",(0,n.jsx)(t.p,{children:"An integral part of our system is giving developers visibility into whether notifications are being delivered successfully and providing a way to debug failures when they happen. Telegraph enables detailed logging across all Lambda functions and gateways using AWS CloudWatch. Though thorough, the sheer volume of logs generated can make diagnosing issues with CloudWatch logs alone difficult."}),"\n",(0,n.jsx)(t.p,{children:"Our dashboard is meant to act as a bridge between visualizing your Telegraph instance and diagnosing problems using CloudWatch logs. It provides a quicker, more user-friendly way to interpret metrics, logs, and failed messages. Developers can use the notification logs generated for a notification request to narrow their search of CloudWatch logs and resolve problems faster."}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/videos/dashboard.gif",className:"diagram",alt:"dashboard"})}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h3,{id:"traffic-spikes",children:"Traffic Spikes"}),"\n",(0,n.jsx)("figure",{className:"image-container",children:(0,n.jsx)("img",{src:"/case-study/images/architecture_queue.png",className:"diagram",alt:"architecture-queue"})}),"\n",(0,n.jsx)(t.p,{children:"Handling traffic spikes is one of the tricky parts of building a notification system. Even though AWS Lambda scales automatically, there are concurrency limits, and DynamoDB, while it auto-scales, has its own read and write rate limits. We wanted to make sure Telegraph could handle sudden surges in traffic without hitting those limits and causing issues. To manage this, we added a queue to rate limit the traffic flowing through the system."}),"\n",(0,n.jsxs)(t.p,{children:["AWS offers two types of queues: FIFO and Standard ",(0,n.jsx)(t.a,{href:"#references",children:"[4]"}),". A FIFO queue, as the name suggests, processes messages in the exact order they are received. This seemed like a nice feature, but it was not strictly necessary for our use case. The downside of a FIFO queue is that it has a throughput limit of 300 requests per second. Also, to preserve the ordering of the messages, if there is an error processing a batch, all unprocessed messages have to go back to the queue. Since the queue uses the number of times a message appears in the queue as its criteria for sending that message to the dead letter queue (DLQ), this meant that it was possible for a message to be sent to the DLQ without ever being attempted to be processed."]}),"\n",(0,n.jsx)(t.p,{children:"A Standard queue forgoes enforcing FIFO behavior and is instead optimized for high message throughput, which Amazon states is unlimited. Without the strict first-in-first-out ordering rules, this meant we could process a batch of messages returning only the failed messages to the queue and eliminate the risk of a valid message being inadvertently sent to the DLQ. With these cumulative benefits, we decided to choose the Standard queue."}),"\n",(0,n.jsx)(t.p,{children:"To then use the queue as a rate limiter in our system, we configured the Lambda consuming from it. The Lambda takes up to 100 messages from the queue with a concurrency limit of 10, creating a ceiling on the number of notification requests that are processed at a given time. Buffering requests and processing them asynchronously allows us to keep downstream components from being overloaded during spikes in traffic."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"load-testing",children:"Load Testing"}),"\n",(0,n.jsxs)(t.p,{children:["To ensure that Telegraph could handle high traffic scenarios and scale effectively, we conducted load testing on the key entry points of the application: the WebSocket Gateway and the HTTP Gateway. The objective of the testing was to evaluate our capacity under heavy loads, focusing on whether the connection requests would be successfully passed on to the integrated lambdas. We simulated a high volume of simultaneous users and interactions using ",(0,n.jsx)(t.code,{children:"artillery.io"})," and a high capacity EC2 instance (32 vCPU, 128 GiB memory)."]}),"\n",(0,n.jsx)(t.h3,{id:"websocket-gateway",children:"WebSocket Gateway"}),"\n",(0,n.jsxs)(t.p,{children:["The WebSocket Gateway was tested to evaluate how it handles a high volume of connections. We started with a low connection rate to establish a baseline and gradually increased the load. Throughout the tests, latency remained consistent, and we didn\u2019t encounter any errors. This confirmed that the WebSocket Gateway can handle up to 500 new connections per second, aligning with AWS's specifications. ",(0,n.jsx)(t.a,{href:"#references",children:"[1]"})]}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Metric"}),(0,n.jsx)(t.th,{children:"Test 1"}),(0,n.jsx)(t.th,{children:"Test 2"}),(0,n.jsx)(t.th,{children:"Test 3"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Test Duration"}),(0,n.jsx)(t.td,{children:"20"}),(0,n.jsx)(t.td,{children:"20"}),(0,n.jsx)(t.td,{children:"600"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Maximum connections per second"}),(0,n.jsx)(t.td,{children:"10"}),(0,n.jsx)(t.td,{children:"200"}),(0,n.jsx)(t.td,{children:"500"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Total Connections"}),(0,n.jsx)(t.td,{children:"200"}),(0,n.jsx)(t.td,{children:"1239"}),(0,n.jsx)(t.td,{children:"291126"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Latency (ms)"}),(0,n.jsx)(t.td,{children:"38"}),(0,n.jsx)(t.td,{children:"26"}),(0,n.jsx)(t.td,{children:"21"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Errors"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"0"})]})]})]}),"\n",(0,n.jsx)(t.h3,{id:"http-gateway",children:"HTTP Gateway"}),"\n",(0,n.jsxs)(t.p,{children:["For the HTTP Gateway, the focus was on API request handling. At light and moderate request rates, the system was able to process all requests. However, at a heavy load of 8,000 requests per second, we hit the AWS Lambda's regional concurrency limit of 1,000 ",(0,n.jsx)(t.a,{href:"#references",children:"[2]"}),". This caused about 1.6% of requests to be throttled, as there weren\u2019t enough Lambdas available to process them. Despite this, the requests that were processed maintained stable latency, and no errors occurred."]}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Metric"}),(0,n.jsx)(t.th,{children:"Test 1"}),(0,n.jsx)(t.th,{children:"Test 2"}),(0,n.jsx)(t.th,{children:"Test 3"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Test Duration (seconds)"}),(0,n.jsx)(t.td,{children:"30"}),(0,n.jsx)(t.td,{children:"60"}),(0,n.jsx)(t.td,{children:"60"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"API Requests per second"}),(0,n.jsx)(t.td,{children:"5"}),(0,n.jsx)(t.td,{children:"100"}),(0,n.jsx)(t.td,{children:"8000"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Total Requests Made"}),(0,n.jsx)(t.td,{children:"150"}),(0,n.jsx)(t.td,{children:"6000"}),(0,n.jsx)(t.td,{children:"480000"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Throttled Requests"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"7854"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Latency (ms)"}),(0,n.jsx)(t.td,{children:"156"}),(0,n.jsx)(t.td,{children:"44"}),(0,n.jsx)(t.td,{children:"78"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"Errors"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"0"}),(0,n.jsx)(t.td,{children:"0"})]})]})]}),"\n",(0,n.jsx)(t.h3,{id:"bottlenecks",children:"Bottlenecks"}),"\n",(0,n.jsx)(t.p,{children:"The main performance bottleneck for Telegraph was the Lambda concurrency limit. While components like API Gateway and DynamoDB scaled well during load tests, Lambda\u2019s default concurrency cap of 1,000 executions per region imposed by AWS became a limiting factor. This limit wasn\u2019t reached during the WebSocket Gateway tests, but when the HTTP Gateway test ramped up to 8,000 requests per second, throttling began as all 1,000 Lambdas were already in use."}),"\n",(0,n.jsx)(t.h3,{id:"capacity",children:"Capacity"}),"\n",(0,n.jsx)(t.p,{children:"Based on our results, we estimate that this bottleneck can be avoided if WebSocket connections are kept under 500 per second and API requests stay below 5,000 per second. These limits align well with our target use case of serving small to medium-sized applications. Moreover, AWS\u2019s flexible concurrency limits offer an additional buffer, allowing Telegraph to scale even further if needed."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"future-work",children:"Future Work"}),"\n",(0,n.jsx)(t.h4,{id:"automated-key-rotation-for-hmac-authentication",children:"Automated Key Rotation for HMAC Authentication"}),"\n",(0,n.jsx)(t.p,{children:"Our HMAC-based authentication approach, while robust, currently has two notable limitations: the lack of expiration and the absence of automated secret key rotation. Automating secret key rotation using a secure key management system like AWS Key Management Service would mitigate risks by periodically updating keys."}),"\n",(0,n.jsx)(t.h4,{id:"stage-specific-metrics",children:"Stage-Specific Metrics"}),"\n",(0,n.jsx)(t.p,{children:"To improve the observability metrics of our dashboard, we could enhance its granularity by providing detailed insights into each stage of the notification delivery pipeline. Currently, the dashboard displays notification logs, their status, and timestamps, but it lacks visibility into where failures occur within the process. By incorporating stage-specific metrics, such as whether the notification failed during API processing, message queueing, or client delivery, we can offer a more precise diagnosis for failures. Additionally, integrating visualizations like success/failure rates, retry attempts, and latency distributions across stages would enable users to understand performance bottlenecks better and identify trends. These improvements would enable users to troubleshoot issues more effectively and optimize their notification workflows."}),"\n",(0,n.jsx)(t.h4,{id:"automating-retry-logic-for-failed-deliveries",children:"Automating Retry Logic for Failed Deliveries"}),"\n",(0,n.jsx)(t.p,{children:"Currently, the system lacks built-in retry logic for failed notification deliveries. While failed deliveries are logged and displayed on the dashboard, any reattempt to send these notifications must be done manually. Introducing automated retry logic to attempt delivery two or three times before marking a notification as failed could reduce the likelihood of prematurely abandoning notifications."}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"footnotes",children:"Footnotes"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Under typical AWS usage scenarios, delivering 10,000 notifications with Telegraph incurs an estimated monthly cost of $14"}),"\n"]}),"\n",(0,n.jsx)(t.hr,{}),"\n",(0,n.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html",children:"https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html",children:"https://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/HMAC",children:"https://en.wikipedia.org/wiki/HMAC"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://aws.amazon.com/sqs",children:"https://aws.amazon.com/sqs"})}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},7644:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/comparison-chart-1294e78ad7b28030ef47765d0f99815c.png"}}]);